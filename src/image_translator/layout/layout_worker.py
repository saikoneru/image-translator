"""
Hi-SAM Layout Detection Worker with FastAPI + BaseWorker
Receives images, detects text layout, assigns OCR words to layout structure.
"""

import json
import numpy as np
import torch
import cv2
import os
import tempfile
from pathlib import Path
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import requests
import base64
import uvicorn
from PIL import Image
from shapely.geometry import Polygon, Point
import pyclipper
import random
from hi_sam.modeling.build import model_registry
from hi_sam.modeling.auto_mask_generator import AutoMaskGenerator
from utils import utilities
from abc import ABC, abstractmethod


# ======================================================
# ðŸ§© Base Worker Interface
# ======================================================
class BaseWorker(ABC):
    @abstractmethod
    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        pass

    @abstractmethod
    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        pass

    @abstractmethod
    def validate_output(self, output_data: Dict[str, Any]) -> bool:
        pass


# ======================================================
# ðŸ§  Hi-SAM Layout Worker Implementation
# ======================================================
class LayoutConfig(BaseModel):
    model_type: str = "vit_l"
    checkpoint: str = "/app/models/hi_sam_l.pth"
    device: str = "cuda"
    total_points: int = 1500
    batch_points: int = 100
    layout_thresh: float = 0.5


class HiSamLayoutWorker(BaseWorker):
    def __init__(self, config: LayoutConfig):
        self.config = config
        self.hisam_model = None
        self.amg = None
        self.initialize_model(config)

    # --------------------------
    # Validation
    # --------------------------
    def validate_input(self, input_data: Dict[str, Any]) -> bool:
        return (
            "image" in input_data
            and isinstance(input_data["image"], np.ndarray)
            and "ocr_results" in input_data
            and isinstance(input_data["ocr_results"], list)
        )

    def validate_output(self, output_data: Dict[str, Any]) -> bool:
        return "paragraphs" in output_data and isinstance(output_data["paragraphs"], list)

    # --------------------------
    # Model Initialization
    # --------------------------
    def initialize_model(self, cfg: LayoutConfig):
        class Args:
            def __init__(self, cfg):
                self.model_type = cfg.model_type
                self.checkpoint = cfg.checkpoint
                self.device = cfg.device
                self.total_points = cfg.total_points
                self.batch_points = cfg.batch_points
                self.hier_det = True
                self.attn_layers = 1
                self.prompt_len = 12
                self.input_size = [1024, 1024]

        args = Args(cfg)
        seed = 42
        torch.manual_seed(seed)
        np.random.seed(seed)
        random.seed(seed)

        self.hisam_model = model_registry[args.model_type](args)
        self.hisam_model.eval()
        self.hisam_model.to(args.device)

        efficient_hisam = args.model_type in ["vit_s", "vit_t"]
        self.amg = AutoMaskGenerator(self.hisam_model, efficient_hisam=efficient_hisam)
        print(f"âœ… Hi-SAM model loaded: {args.model_type}")

    # --------------------------
    # Helper Functions
    # --------------------------
    def unclip(self, p, unclip_ratio=2.0):
        poly = Polygon(p)
        distance = poly.area * unclip_ratio / poly.length
        offset = pyclipper.PyclipperOffset()
        offset.AddPath(p, pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)
        expanded = np.array(offset.Execute(distance))
        return expanded

    def process_image_layout(self, image: np.ndarray) -> Dict[str, Any]:
        cfg = self.config
        amg = self.amg
        img_h, img_w = image.shape[:2]
        amg.set_image(image)

        masks, scores, affinity = amg.predict(
            from_low_res=False,
            fg_points_num=cfg.total_points,
            batch_points_num=cfg.batch_points,
            score_thresh=0.5,
            nms_thresh=0.5,
        )

        if masks is None:
            return {"paragraphs": [{"lines": [{"words": []}]}]}

        masks = (masks[:, 0, :, :]).astype(np.uint8)
        lines, line_indices = [], []

        for index, mask in enumerate(masks):
            line = {"words": []}
            contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

            for cont in contours:
                epsilon = 0.002 * cv2.arcLength(cont, True)
                approx = cv2.approxPolyDP(cont, epsilon, True)
                points = approx.reshape((-1, 2))
                if points.shape[0] < 4:
                    continue
                pts = self.unclip(points)
                if len(pts) != 1:
                    continue
                pts = pts[0].astype(np.int32)
                if Polygon(pts).area < 32:
                    continue
                pts[:, 0] = np.clip(pts[:, 0], 0, img_w)
                pts[:, 1] = np.clip(pts[:, 1], 0, img_h)
                line["words"].append({"vertices": pts.tolist()})

            if line["words"]:
                lines.append(line)
                line_indices.append(index)

        line_grouping = utilities.DisjointSet(len(line_indices))
        affinity = affinity[line_indices][:, line_indices]
        for i1, i2 in zip(*np.where(affinity > cfg.layout_thresh)):
            line_grouping.union(i1, i2)

        line_groups = line_grouping.to_group()
        paragraphs = []
        for group in line_groups:
            paragraphs.append({"lines": [lines[i] for i in group]})

        return {"paragraphs": paragraphs}

    def assign_words_to_masks(self, ocr_results, layout_result):
        paragraphs_out = []
        assigned_ids = set()
        layout_paragraphs = layout_result.get("paragraphs", [])
        if not ocr_results:
            return []
        ocr_results = [w for w in ocr_results if str(w.get("text", "")).strip()]

        for p_idx, para in enumerate(layout_paragraphs):
            para_out = {"paragraph_index": p_idx, "lines": []}
            for l_idx, line in enumerate(para.get("lines", [])):
                line_out = {"line_index": l_idx, "words": []}
                line_pts = []
                for word in line.get("words", []):
                    verts = np.array(word.get("vertices", []), dtype=np.float32)
                    if len(verts) >= 3:
                        line_pts.extend(verts.tolist())
                if len(line_pts) < 3:
                    continue
                line_poly = Polygon(line_pts)
                for i, word in enumerate(ocr_results):
                    if i in assigned_ids:
                        continue
                    box = np.array(word["box"], dtype=np.float32)
                    cx, cy = np.mean(box[:, 0]), np.mean(box[:, 1])
                    pt = Point(cx, cy)
                    if line_poly.contains(pt) or line_poly.distance(pt) < 5:
                        line_out["words"].append(word)
                        assigned_ids.add(i)
                if line_out["words"]:
                    line_out["words"].sort(key=lambda w: np.mean([pt[0] for pt in w["box"]]))
                    para_out["lines"].append(line_out)
            if para_out["lines"]:
                paragraphs_out.append(para_out)

        unassigned = [ocr_results[i] for i in range(len(ocr_results)) if i not in assigned_ids]
        for word in unassigned:
            paragraphs_out.append({
                "paragraph_index": len(paragraphs_out),
                "lines": [{"line_index": 0, "words": [word]}]
            })
        return paragraphs_out

    def sort_and_reindex_hierarchy(self, hierarchy):
        sorted_paragraphs = []
        for para in sorted(hierarchy, key=lambda p: np.mean([w["box"][0][1] for w in p["lines"][0]["words"]]) if p["lines"] else float("inf")):
            sorted_lines = []
            for line in sorted(para["lines"], key=lambda l: np.mean([pt[1] for w in l["words"] for pt in w["box"]]) if l["words"] else float("inf")):
                filtered_words = [w for w in line["words"] if w.get("text") and w["text"].strip()]
                if not filtered_words:
                    continue
                filtered_words = sorted(filtered_words, key=lambda w: np.mean([pt[0] for pt in w["box"]]))
                sorted_lines.append({"line_index": len(sorted_lines), "words": filtered_words})
            if sorted_lines:
                sorted_paragraphs.append({"paragraph_index": len(sorted_paragraphs), "lines": sorted_lines})
        return sorted_paragraphs

    def convert_hierarchy_to_paragraphs(self, hierarchy_sorted):
        paragraphs_list = []
        for para in hierarchy_sorted:
            para_lines = []
            for line in para["lines"]:
                line_text = " ".join([word.get("text", "") for word in line["words"]])
                all_pts = np.vstack([np.array(word["box"]) for word in line["words"]])
                x_min, y_min = np.min(all_pts[:, 0]), np.min(all_pts[:, 1])
                x_max, y_max = np.max(all_pts[:, 0]), np.max(all_pts[:, 1])
                box = [[int(x_min), int(y_min)], [int(x_max), int(y_min)],
                       [int(x_max), int(y_max)], [int(x_min), int(y_max)]]
                para_lines.append({"text": line_text, "box": box})
            paragraphs_list.append(para_lines)
        return paragraphs_list

    # --------------------------
    # Unified Process Interface
    # --------------------------
    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        if not self.validate_input(input_data):
            raise ValueError("Invalid input format for Hi-SAM worker")

        image_rgb = cv2.cvtColor(input_data["image"], cv2.COLOR_BGR2RGB)
        layout_result = self.process_image_layout(image_rgb)
        hierarchy = self.assign_words_to_masks(input_data["ocr_results"], layout_result)
        hierarchy_sorted = self.sort_and_reindex_hierarchy(hierarchy)
        paragraphs = self.convert_hierarchy_to_paragraphs(hierarchy_sorted)

        output = {"paragraphs": paragraphs}
        if not self.validate_output(output):
            raise ValueError("Invalid output format")

        return output


# ======================================================
# ðŸš€ FastAPI Integration
# ======================================================
app = FastAPI(title="Hi-SAM Layout Worker with BaseWorker")
worker = HiSamLayoutWorker(LayoutConfig())


@app.post("/detect_layout")
async def detect_layout(file: UploadFile = File(...), ocr_results_json: str = Form(...)):
    try:
        contents = await file.read()
        nparr = np.frombuffer(contents, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if image is None:
            raise HTTPException(status_code=400, detail="Failed to decode image")

        ocr_results = json.loads(ocr_results_json)
        input_data = {"image": image, "ocr_results": ocr_results}
        result = worker.process(input_data)
        return JSONResponse(content={"success": True, **result})

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/")
async def root():
    return {"status": "running", "model": worker.config.model_type}


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8005, log_level="debug")
